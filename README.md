# ğŸš¦ Copenhagen Traffic Congestion ETL Project (AWS Cloud)

## ğŸ“Œ Project Summary

This project builds a data engineering pipeline for monitoring and analyzing traffic congestion in Copenhagen using AWS cloud services. It covers ingestion, cataloging, transformation, querying, and visualization of traffic data.

## â˜ï¸ AWS Services Used

- **Amazon S3** â€“ Store raw and processed traffic data
- **AWS Glue Crawler** â€“ Automatically detect schema from CSV files
- **AWS Glue Job (PySpark)** â€“ Clean and transform traffic data
- **Amazon Athena** â€“ Query traffic data using SQL
- **Amazon QuickSight** â€“ Visualize congestion levels by location and time

## ğŸ§± Architecture

1. CSV files uploaded to S3
2. Glue Crawler catalogs schema into Glue Data Catalog
3. Glue ETL Job transforms and cleans the data
4. Processed data stored in a new S3 path
5. Athena queries the cleaned data
6. QuickSight builds dashboards from Athena output

(ğŸ“¸ Architecture diagram: `docs/architecture.png` - add manually)

## ğŸ” ETL Pipeline Steps

1. Upload raw traffic data to S3
2. Use Glue Crawler to catalog data into `traffic_db`
3. Glue Job drops nulls and formats timestamps
4. Store cleaned data to `s3://<your-bucket>/processed/`
5. Query data in Athena
6. Build dashboard in QuickSight

## ğŸ“Š Sample Queries (Athena)

```sql
SELECT location, AVG(congestion_level) as avg_congestion
FROM traffic_db.cleaned_traffic_data
GROUP BY location
ORDER BY avg_congestion DESC;
```

## ğŸ“¸ Screenshots

Add screenshots in `docs/screenshots/`:
- S3 Upload
- Glue Crawler
- Glue Job Script
- Athena Query
- QuickSight Dashboard

## ğŸš€ How to Run

1. Clone this repo
2. Upload the sample CSV to your S3 bucket
3. Follow README steps to recreate pipeline
4. Use Athena + QuickSight for analysis

## ğŸ“ What I Learned

- How to design cloud-based ETL with AWS Glue
- PySpark for data cleaning
- Serverless querying with Athena
- Building dashboards with QuickSight

---
